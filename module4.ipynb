{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eda126d",
   "metadata": {},
   "source": [
    "# TMDB Movie Data Analysis using Spark and APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c576225",
   "metadata": {},
   "source": [
    "## Step 1: API Setup and Data Extraction\n",
    "\n",
    "This section focuses on setting up the TMDB API connection and extracting movie data. We'll use PySpark for distributed data processing and the TMDB API to fetch detailed movie information including cast, crew, and financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da82377",
   "metadata": {},
   "source": [
    "### Import Necessary Modules\n",
    "\n",
    "Start by importing the required libraries for:\n",
    "- **PySpark**: Distributed data processing and analysis\n",
    "- **API calls**: HTTP requests to TMDB API\n",
    "- **Data manipulation**: NumPy for numerical operations\n",
    "- **Environment management**: Secure API key handling\n",
    "- **Visualization**: Matplotlib for data plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d081b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session for distributed data processing\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create Spark session with adaptive query execution enabled\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"TMDB Movie Data Analysis\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976e07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries for API calls and data analysis\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time  # For handling API rate limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env_setup",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "Load environment variables from .env file to securely access the TMDB API key without hardcoding sensitive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d2bfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api_key_setup",
   "metadata": {},
   "source": [
    "### API Key Configuration\n",
    "\n",
    "Retrieve the TMDB API key from environment variables. This approach ensures:\n",
    "- Security: API keys are not exposed in code\n",
    "- Flexibility: Easy to change keys without code modification\n",
    "- Best practices: Following secure development standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e981e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve TMDB API key from environment variables\n",
    "API_KEY = os.getenv('TMDB_API_KEY')\n",
    "\n",
    "# Validate API key is loaded\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"TMDB_API_KEY not found in environment variables. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "movie_data_fetch",
   "metadata": {},
   "source": [
    "### Movie Data Extraction with Error Handling\n",
    "\n",
    "This section implements robust movie data fetching with comprehensive error handling:\n",
    "\n",
    "**Features:**\n",
    "- **Timeout handling**: Prevents hanging requests\n",
    "- **HTTP error handling**: Manages API response errors\n",
    "- **Connection error handling**: Handles network issues\n",
    "- **Rate limiting**: Respects API usage limits\n",
    "- **Data validation**: Ensures safe data access\n",
    "- **Progress tracking**: Shows real-time processing status\n",
    "\n",
    "**Data collected for each movie:**\n",
    "- Basic info: Title, release date, runtime, budget, revenue\n",
    "- Ratings: Vote average and count\n",
    "- Cast: Top 5 actors and total cast size\n",
    "- Crew: Director and total crew size\n",
    "- Genres and production details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8709922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting movie data extraction...\n",
      "Processing movie 1/19 (ID: 0)... Failed to fetch movie with ID: 0\n",
      "Processing movie 2/19 (ID: 299534)... Fetched movie: Avengers: Endgame (ID: 299534)\n",
      "Processing movie 3/19 (ID: 19995)... Fetched movie: Avatar (ID: 19995)\n",
      "Processing movie 4/19 (ID: 140607)... Fetched movie: Star Wars: The Force Awakens (ID: 140607)\n",
      "Processing movie 5/19 (ID: 299536)... Fetched movie: Avengers: Infinity War (ID: 299536)\n",
      "Processing movie 6/19 (ID: 597)... Fetched movie: Titanic (ID: 597)\n",
      "Processing movie 7/19 (ID: 135397)... Fetched movie: Jurassic World (ID: 135397)\n",
      "Processing movie 8/19 (ID: 420818)... Fetched movie: The Lion King (ID: 420818)\n",
      "Processing movie 9/19 (ID: 24428)... Fetched movie: The Avengers (ID: 24428)\n",
      "Processing movie 10/19 (ID: 168259)... Fetched movie: Furious 7 (ID: 168259)\n",
      "Processing movie 11/19 (ID: 99861)... Fetched movie: Avengers: Age of Ultron (ID: 99861)\n",
      "Processing movie 12/19 (ID: 284054)... Fetched movie: Black Panther (ID: 284054)\n",
      "Processing movie 13/19 (ID: 12445)... Fetched movie: Harry Potter and the Deathly Hallows: Part 2 (ID: 12445)\n",
      "Processing movie 14/19 (ID: 181808)... Fetched movie: Star Wars: The Last Jedi (ID: 181808)\n",
      "Processing movie 15/19 (ID: 330457)... Fetched movie: Frozen II (ID: 330457)\n",
      "Processing movie 16/19 (ID: 351286)... Fetched movie: Jurassic World: Fallen Kingdom (ID: 351286)\n",
      "Processing movie 17/19 (ID: 109445)... Fetched movie: Frozen (ID: 109445)\n",
      "Processing movie 18/19 (ID: 321612)... Fetched movie: Beauty and the Beast (ID: 321612)\n",
      "Processing movie 19/19 (ID: 260513)... Fetched movie: Incredibles 2 (ID: 260513)\n",
      "\n",
      "=== Data Extraction Summary ===\n",
      "Total movies requested: 19\n",
      "Successfully fetched: 18\n",
      "Failed requests: 1\n",
      "\n",
      "Failed requests details:\n",
      "  - Movie ID 0: HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "# List of popular movie IDs from TMDB (including one invalid ID for testing error handling)\n",
    "movie_ids = [\n",
    "    0, 299534, 19995, 140607, 299536, 597, 135397,\n",
    "    420818, 24428, 168259, 99861, 284054, 12445,\n",
    "    181808, 330457, 351286, 109445, 321612, 260513\n",
    "]\n",
    "\n",
    "# TMDB API configuration\n",
    "base_url = \"https://api.themoviedb.org/3/movie\"\n",
    "params = {\"api_key\": API_KEY, \"language\": \"en-US\"}\n",
    "\n",
    "# Initialize lists to store results\n",
    "movies_data = []\n",
    "failed_requests = []  # Track failed requests for analysis\n",
    "\n",
    "print(\"Starting movie data extraction...\")\n",
    "\n",
    "for i, movie_id in enumerate(movie_ids, 1):\n",
    "    try:\n",
    "        print(f\"Processing movie {i}/{len(movie_ids)} (ID: {movie_id})...\", end=\" \")\n",
    "        \n",
    "        # Fetch movie details with timeout and error handling\n",
    "        movie_url = f\"{base_url}/{movie_id}\"\n",
    "        movie_response = requests.get(movie_url, params=params, timeout=10)\n",
    "        movie_response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "        \n",
    "        data = movie_response.json()\n",
    "        \n",
    "        # Fetch credits with nested error handling\n",
    "        try:\n",
    "            credits_url = f\"{base_url}/{movie_id}/credits\"\n",
    "            credits_response = requests.get(credits_url, params=params, timeout=10)\n",
    "            credits_response.raise_for_status()\n",
    "            \n",
    "            credits = credits_response.json()\n",
    "            \n",
    "            # Extract main cast (top 5 names) with safe access\n",
    "            cast_list = [member.get(\"name\", \"Unknown\") for member in credits.get(\"cast\", [])[:5]]\n",
    "            cast_names = \"|\".join(cast_list) if cast_list else \"No cast data\"\n",
    "            cast_size = len(credits.get(\"cast\", []))\n",
    "            \n",
    "            # Extract directors from crew with safe access\n",
    "            crew = credits.get(\"crew\", [])\n",
    "            directors = [m.get(\"name\") for m in crew if m.get(\"job\") == \"Director\" and m.get(\"name\")]\n",
    "            director_name = directors[0] if directors else \"Unknown Director\"\n",
    "            crew_size = len(crew)\n",
    "            \n",
    "            # Add credit info to movie data\n",
    "            data[\"cast\"] = cast_names\n",
    "            data[\"cast_size\"] = cast_size\n",
    "            data[\"director\"] = director_name\n",
    "            data[\"crew_size\"] = crew_size\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Credits fetch failed: {str(e)[:50]}...\")\n",
    "            # Set default values if credits fetch fails\n",
    "            data[\"cast\"] = \"Credits unavailable\"\n",
    "            data[\"cast_size\"] = 0\n",
    "            data[\"director\"] = \"Unknown Director\"\n",
    "            data[\"crew_size\"] = 0\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Credits processing error: {str(e)[:50]}...\")\n",
    "            data[\"cast\"] = \"Processing error\"\n",
    "            data[\"cast_size\"] = 0\n",
    "            data[\"director\"] = \"Unknown Director\"\n",
    "            data[\"crew_size\"] = 0\n",
    "        \n",
    "        movies_data.append(data)\n",
    "        print(f\"Fetched movie: {data.get('title', 'Unknown Title')} (ID: {movie_id})\")\n",
    "        \n",
    "        # Add small delay to respect API rate limits\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        error_msg = f\"HTTP Error {e.response.status_code}: {e.response.reason}\"\n",
    "        print(f\"Failed to fetch movie with ID: {movie_id}\")\n",
    "        failed_requests.append({\"movie_id\": movie_id, \"error\": error_msg})\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        error_msg = \"Request timeout (>10s)\"\n",
    "        print(f\"Timeout error for movie ID: {movie_id}\")\n",
    "        failed_requests.append({\"movie_id\": movie_id, \"error\": error_msg})\n",
    "        \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        error_msg = \"Connection error - check internet connection\"\n",
    "        print(f\"Connection error for movie ID: {movie_id}\")\n",
    "        failed_requests.append({\"movie_id\": movie_id, \"error\": error_msg})\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"Request error: {str(e)[:50]}...\"\n",
    "        print(f\"Request error for movie ID: {movie_id}\")\n",
    "        failed_requests.append({\"movie_id\": movie_id, \"error\": error_msg})\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected error: {str(e)[:50]}...\"\n",
    "        print(f\"Unexpected error for movie ID: {movie_id}\")\n",
    "        failed_requests.append({\"movie_id\": movie_id, \"error\": error_msg})\n",
    "\n",
    "# Summary of data extraction\n",
    "print(f\"\\n=== Data Extraction Summary ===\")\n",
    "print(f\"Total movies requested: {len(movie_ids)}\")\n",
    "print(f\"Successfully fetched: {len(movies_data)}\")\n",
    "print(f\"Failed requests: {len(failed_requests)}\")\n",
    "\n",
    "if failed_requests:\n",
    "    print(\"\\nFailed requests details:\")\n",
    "    for failure in failed_requests:\n",
    "        print(f\"  - Movie ID {failure['movie_id']}: {failure['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebf1df",
   "metadata": {},
   "source": [
    "## Convert movies_data to Saprk DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce9324c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame with 18 movies\n",
      "DataFrame columns: 30\n",
      "+----------------------------+------------+------------+---------+----------+\n",
      "|title                       |release_date|vote_average|budget   |revenue   |\n",
      "+----------------------------+------------+------------+---------+----------+\n",
      "|Avengers: Endgame           |2019-04-24  |8.2         |356000000|2799439100|\n",
      "|Avatar                      |2009-12-15  |7.594       |237000000|2923706026|\n",
      "|Star Wars: The Force Awakens|2015-12-15  |7.255       |245000000|2068223624|\n",
      "+----------------------------+------------+------------+---------+----------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Create Spark DataFrame from movies_data\n",
    "df = spark.createDataFrame(movies_data)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Created DataFrame with {df.count()} movies\")\n",
    "print(f\"DataFrame columns: {len(df.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "df.select('title', 'release_date', 'vote_average', 'budget', 'revenue').show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5627c2",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Preprocessing\n",
    "\n",
    "### Data Preparation & Cleaning\n",
    "\n",
    "1. **Drop** irrelevant columns: ['adult', 'imdb_id', 'original_title', 'video', 'homepage']\n",
    "2. **Evaluate** JSON-like columns (['belongs_to_collection', 'genres', 'production_countries', 'production_companies', 'spoken_languages'])\n",
    "3. **Extract** and clean key data points:\n",
    "   - Collection name (belongs_to_collection)\n",
    "   - Genre names (genres → separate multiple genres with \"|\")\n",
    "   - Spoken languages (spoken_languages → separate with \"|\")\n",
    "   - Production countries (production_countries → separate with \"|\")\n",
    "   - Production companies (production_companies → separate with \"|\")\n",
    "4. **Inspect** extracted columns using value_counts() to identify anomalies\n",
    "\n",
    "### Handling Missing & Incorrect Data\n",
    "\n",
    "5. **Convert** column datatypes:\n",
    "   - 'budget', 'id', 'popularity' → Numeric (set invalid values to NaN)\n",
    "   - 'release_date' → Convert to datetime\n",
    "6. **Replace unrealistic values**:\n",
    "   - Budget/Revenue/Runtime = 0 → Replace with NaN\n",
    "   - Convert 'budget' and 'revenue' to million USD\n",
    "   - Movies with vote_count = 0 → Analyze their vote_average and adjust accordingly\n",
    "   - 'overview' and 'tagline' → Replace known placeholders (e.g., 'No Data') with NaN\n",
    "7. **Remove duplicates** and drop rows with unknown 'id' or 'title'\n",
    "8. **Keep** only rows where at least **10 columns have non-NaN values**\n",
    "9. **Filter** to include only 'Released' movies, then drop 'status'\n",
    "\n",
    "### Reorder & Finalize DataFrame\n",
    "\n",
    "10. **Reorder columns**: ['id', 'title', 'tagline', 'release_date', 'genres', 'belongs_to_collection', 'original_language', 'budget_musd', 'revenue_musd', 'production_companies', 'production_countries', 'vote_count', 'vote_average', 'popularity', 'runtime', 'overview', 'spoken_languages', 'poster_path', 'cast', 'cast_size', 'director', 'crew_size']\n",
    "11. **Reset index**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb0c11",
   "metadata": {},
   "source": [
    "### 2.1 Drop irrelevant columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c9ba901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['backdrop_path',\n",
       " 'belongs_to_collection',\n",
       " 'budget',\n",
       " 'cast',\n",
       " 'cast_size',\n",
       " 'crew_size',\n",
       " 'director',\n",
       " 'genres',\n",
       " 'id',\n",
       " 'origin_country',\n",
       " 'original_language',\n",
       " 'overview',\n",
       " 'popularity',\n",
       " 'poster_path',\n",
       " 'production_companies',\n",
       " 'production_countries',\n",
       " 'release_date',\n",
       " 'revenue',\n",
       " 'runtime',\n",
       " 'spoken_languages',\n",
       " 'status',\n",
       " 'tagline',\n",
       " 'title',\n",
       " 'vote_average',\n",
       " 'vote_count']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = ['adult', 'imdb_id', 'original_title', 'video', 'homepage']\n",
    "df1 = df.drop(*cols_to_drop)\n",
    "\n",
    "print(f\"Columns after dropping: {len(df.columns)}\")\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d292eee",
   "metadata": {},
   "source": [
    "### 2.2  Evaluate JSON-like columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bf3db54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: collection_name\n",
      "+--------------------+-----+\n",
      "|     collection_name|count|\n",
      "+--------------------+-----+\n",
      "|The Avengers Coll...|    4|\n",
      "|Star Wars Collection|    2|\n",
      "|                NULL|    2|\n",
      "|Jurassic Park Col...|    2|\n",
      "|   Frozen Collection|    2|\n",
      "|   Avatar Collection|    1|\n",
      "|The Lion King (Re...|    1|\n",
      "|The Fast and the ...|    1|\n",
      "|Harry Potter Coll...|    1|\n",
      "|Black Panther Col...|    1|\n",
      "|The Incredibles C...|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "\n",
      "Column: genres_clean\n",
      "+--------------------+-----+\n",
      "|        genres_clean|count|\n",
      "+--------------------+-----+\n",
      "|\"Adventure\",\"id\":...|    3|\n",
      "|\"Action\",\"id\":\"28...|    2|\n",
      "|\"Action\",\"id\":\"28...|    2|\n",
      "|\"Action\",\"id\":\"28...|    1|\n",
      "|\"Adventure\",\"id\":...|    1|\n",
      "|\"Drama\",\"id\":\"18\"...|    1|\n",
      "|\"Science Fiction\"...|    1|\n",
      "|\"Adventure\",\"id\":...|    1|\n",
      "|\"Action\",\"id\":\"28...|    1|\n",
      "|\"Adventure\",\"id\":...|    1|\n",
      "|\"Family\",\"id\":\"10...|    1|\n",
      "|\"Family\",\"id\":\"10...|    1|\n",
      "|\"Action\",\"id\":\"28...|    1|\n",
      "|\"Animation\",\"id\":...|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "\n",
      "Column: spoken_languages_clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|spoken_languages_clean|count|\n",
      "+----------------------+-----+\n",
      "|  \"name\":\"English\",...|    9|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"العربية\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "+----------------------+-----+\n",
      "\n",
      "\n",
      "Column: production_countries_clean\n",
      "+--------------------------+-----+\n",
      "|production_countries_clean|count|\n",
      "+--------------------------+-----+\n",
      "|      \"United States of...|   16|\n",
      "|      \"United States of...|    1|\n",
      "|      \"United Kingdom\",...|    1|\n",
      "+--------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix the JSON cleaning with simpler regex patterns\n",
    "df2 = df1.withColumn(\"collection_name\", \n",
    "    when(col(\"belongs_to_collection\").isNotNull(), \n",
    "         col(\"belongs_to_collection\")[\"name\"])\n",
    "    .otherwise(None))\n",
    "\n",
    "df2 = df2.withColumn(\"genres_clean\", \n",
    "    regexp_replace(\n",
    "        regexp_replace(to_json(col(\"genres\")), \"\\\\[|\\\\]|\\\\{|\\\\}\", \"\"),\n",
    "        '\"name\":', \"\"\n",
    "    ))\n",
    "\n",
    "df2 = df2.withColumn(\"production_countries_clean\",\n",
    "    regexp_replace(\n",
    "        regexp_replace(to_json(col(\"production_countries\")), \"\\\\[|\\\\]|\\\\{|\\\\}\", \"\"),\n",
    "        '\"name\":', \"\"\n",
    "    ))\n",
    "\n",
    "df2 = df2.withColumn(\"production_companies_clean\",\n",
    "    regexp_replace(\n",
    "        regexp_replace(to_json(col(\"production_companies\")), \"\\\\[|\\\\]|\\\\{|\\\\}\", \"\"),\n",
    "        '\"name\":', \"\"\n",
    "    ))\n",
    "\n",
    "df2 = df2.withColumn(\"spoken_languages_clean\",\n",
    "    regexp_replace(\n",
    "        regexp_replace(to_json(col(\"spoken_languages\")), \"\\\\[|\\\\]|\\\\{|\\\\}\", \"\"),\n",
    "        '\"english_name\":', \"\"\n",
    "    ))\n",
    "\n",
    "df2 = df2.drop(\"belongs_to_collection\")\n",
    "\n",
    "# Inspect extracted columns using value_counts\n",
    "for col_name in [\"collection_name\", \"genres_clean\", \"spoken_languages_clean\", \"production_countries_clean\"]:\n",
    "    print(f\"\\nColumn: {col_name}\")\n",
    "    df2.groupBy(col_name).count().orderBy(desc(\"count\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e73ca303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: collection_name\n",
      "+--------------------+-----+\n",
      "|     collection_name|count|\n",
      "+--------------------+-----+\n",
      "|The Avengers Coll...|    4|\n",
      "|Star Wars Collection|    2|\n",
      "|                NULL|    2|\n",
      "|Jurassic Park Col...|    2|\n",
      "|   Frozen Collection|    2|\n",
      "|   Avatar Collection|    1|\n",
      "|The Lion King (Re...|    1|\n",
      "|The Fast and the ...|    1|\n",
      "|Harry Potter Coll...|    1|\n",
      "|Black Panther Col...|    1|\n",
      "|The Incredibles C...|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "\n",
      "Column: genres_clean\n",
      "+--------------------+-----+\n",
      "|        genres_clean|count|\n",
      "+--------------------+-----+\n",
      "|\"Adventure\",\"id\":...|    3|\n",
      "|\"Action\",\"id\":\"28...|    2|\n",
      "|\"Action\",\"id\":\"28...|    2|\n",
      "|\"Action\",\"id\":\"28...|    1|\n",
      "|\"Adventure\",\"id\":...|    1|\n",
      "|\"Drama\",\"id\":\"18\"...|    1|\n",
      "|\"Science Fiction\"...|    1|\n",
      "|\"Adventure\",\"id\":...|    1|\n",
      "|\"Action\",\"id\":\"28...|    1|\n",
      "|\"Adventure\",\"id\":...|    1|\n",
      "|\"Family\",\"id\":\"10...|    1|\n",
      "|\"Family\",\"id\":\"10...|    1|\n",
      "|\"Action\",\"id\":\"28...|    1|\n",
      "|\"Animation\",\"id\":...|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "\n",
      "Column: spoken_languages_clean\n",
      "+----------------------+-----+\n",
      "|spoken_languages_clean|count|\n",
      "+----------------------+-----+\n",
      "|  \"name\":\"English\",...|    9|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"العربية\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "|  \"name\":\"English\",...|    1|\n",
      "+----------------------+-----+\n",
      "\n",
      "\n",
      "Column: production_countries_clean\n",
      "+--------------------------+-----+\n",
      "|production_countries_clean|count|\n",
      "+--------------------------+-----+\n",
      "|      \"United States of...|   16|\n",
      "|      \"United States of...|    1|\n",
      "|      \"United Kingdom\",...|    1|\n",
      "+--------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect extracted columns using value_counts\n",
    "for col_name in [\"collection_name\", \"genres_clean\", \"spoken_languages_clean\", \"production_countries_clean\"]:\n",
    "    print(f\"\\nColumn: {col_name}\")\n",
    "    df2.groupBy(col_name).count().orderBy(desc(\"count\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45d3c9",
   "metadata": {},
   "source": [
    "### 2.3 Extract and clean key data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d16e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection name\n",
    "df2 = df1.withColumn(\"collection_name\", \n",
    "    when(col(\"belongs_to_collection\").isNotNull(), \n",
    "         col(\"belongs_to_collection\")[\"name\"])\n",
    "    .otherwise(None))\n",
    "\n",
    "# Genre names (separate with \"|\")\n",
    "df2 = df2.withColumn(\"genres_clean\", \n",
    "    expr(\"transform(genres, x -> x.name)\")).withColumn(\"genres_clean\", \n",
    "    concat_ws(\"|\", col(\"genres_clean\")))\n",
    "\n",
    "# Spoken languages (separate with \"|\")\n",
    "df2 = df2.withColumn(\"spoken_languages_clean\",\n",
    "    expr(\"transform(spoken_languages, x -> x.english_name)\")).withColumn(\"spoken_languages_clean\",\n",
    "    concat_ws(\"|\", col(\"spoken_languages_clean\")))\n",
    "\n",
    "# Production countries (separate with \"|\")\n",
    "df2 = df2.withColumn(\"production_countries_clean\",\n",
    "    expr(\"transform(production_countries, x -> x.name)\")).withColumn(\"production_countries_clean\",\n",
    "    concat_ws(\"|\", col(\"production_countries_clean\")))\n",
    "\n",
    "# Production companies (separate with \"|\")\n",
    "df2 = df2.withColumn(\"production_companies_clean\",\n",
    "    expr(\"transform(production_companies, x -> x.name)\")).withColumn(\"production_companies_clean\",\n",
    "    concat_ws(\"|\", col(\"production_companies_clean\")))\n",
    "\n",
    "df2 = df2.drop(\"belongs_to_collection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b53e4",
   "metadata": {},
   "source": [
    "### 2.4 Inspect Extracted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63cd224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: collection_name\n",
      "+--------------------+-----+\n",
      "|     collection_name|count|\n",
      "+--------------------+-----+\n",
      "|The Avengers Coll...|    4|\n",
      "|Star Wars Collection|    2|\n",
      "|                NULL|    2|\n",
      "|Jurassic Park Col...|    2|\n",
      "|   Frozen Collection|    2|\n",
      "|   Avatar Collection|    1|\n",
      "|The Lion King (Re...|    1|\n",
      "|The Fast and the ...|    1|\n",
      "|Harry Potter Coll...|    1|\n",
      "|Black Panther Col...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Column: genres_clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        genres_clean|count|\n",
      "+--------------------+-----+\n",
      "|Adventure|Action|...|    3|\n",
      "|Action|Adventure|...|    2|\n",
      "|Action|Adventure|...|    2|\n",
      "|Adventure|Science...|    1|\n",
      "|Action|Adventure|...|    1|\n",
      "|       Drama|Romance|    1|\n",
      "|Adventure|Drama|F...|    1|\n",
      "|Science Fiction|A...|    1|\n",
      "|Action|Crime|Thri...|    1|\n",
      "|   Adventure|Fantasy|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Column: spoken_languages_clean\n",
      "+----------------------+-----+\n",
      "|spoken_languages_clean|count|\n",
      "+----------------------+-----+\n",
      "|               English|    9|\n",
      "|       English|Spanish|    1|\n",
      "|  English|Japanese|...|    1|\n",
      "|         English|Xhosa|    1|\n",
      "|  English|French|Ge...|    1|\n",
      "|  English|Hindi|Rus...|    1|\n",
      "|  Arabic|English|Sp...|    1|\n",
      "|  English|Korean|Sw...|    1|\n",
      "|       English|Russian|    1|\n",
      "|        English|French|    1|\n",
      "+----------------------+-----+\n",
      "\n",
      "\n",
      "Column: production_countries_clean\n",
      "+--------------------------+-----+\n",
      "|production_countries_clean|count|\n",
      "+--------------------------+-----+\n",
      "|      United States of ...|   16|\n",
      "|      United States of ...|    1|\n",
      "|      United Kingdom|Un...|    1|\n",
      "+--------------------------+-----+\n",
      "\n",
      "\n",
      "Column: production_companies_clean\n",
      "+--------------------------+-----+\n",
      "|production_companies_clean|count|\n",
      "+--------------------------+-----+\n",
      "|            Marvel Studios|    5|\n",
      "|      Walt Disney Anima...|    2|\n",
      "|      Dune Entertainmen...|    1|\n",
      "|      Lucasfilm Ltd.|Ba...|    1|\n",
      "|      Amblin Entertainm...|    1|\n",
      "|      Paramount Picture...|    1|\n",
      "|      Walt Disney Pictu...|    1|\n",
      "|      Original Film|One...|    1|\n",
      "|      Warner Bros. Pict...|    1|\n",
      "|            Lucasfilm Ltd.|    1|\n",
      "+--------------------------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Inspect extracted columns using value_counts to identify anomalies\n",
    "for col_name in [\"collection_name\", \"genres_clean\", \"spoken_languages_clean\", \"production_countries_clean\", \"production_companies_clean\"]:\n",
    "    print(f\"\\nColumn: {col_name}\")\n",
    "    df2.groupBy(col_name).count().orderBy(desc(\"count\")).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d31fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
